{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from model import model, dummy_loss\n",
    "from utils.generator import create_batch\n",
    "from utils.utils import normalize, evaluate, makedirs,read_annotations\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from utils.callbacks import CustomModelCheckpoint, CustomTensorBoard\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from utils.multi_gpu_model import multi_gpu_model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_instances(\n",
    "    train_annot_folder,\n",
    "    train_image_folder,\n",
    "    train_cache,\n",
    "    valid_annot_folder,\n",
    "    valid_image_folder,\n",
    "    valid_cache,\n",
    "    labels,\n",
    "):\n",
    "    # parse annotations of the training set\n",
    "    train_ints, train_labels = read_annotations(train_annot_folder, train_image_folder, train_cache, labels)\n",
    "\n",
    "    # parse annotations of the validation set, if any, otherwise split the training set\n",
    "    if os.path.exists(valid_annot_folder):\n",
    "        valid_ints, valid_labels = read_annotations(valid_annot_folder, valid_image_folder, valid_cache, labels)\n",
    "    else:\n",
    "        print(\"valid_annot_folder not exists. Spliting the trainining set.\")\n",
    "\n",
    "        train_valid_split = int(0.8*len(train_ints))\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(train_ints)\n",
    "        np.random.seed()\n",
    "\n",
    "        valid_ints = train_ints[train_valid_split:]\n",
    "        train_ints = train_ints[:train_valid_split]\n",
    "\n",
    "    # compare the seen labels with the given labels in config.json\n",
    "    max_box_per_image = max([len(inst['object']) for inst in (train_ints + valid_ints)])\n",
    "    if len(labels) > 0:\n",
    "        overlap_labels = set(labels).intersection(set(train_labels.keys()))\n",
    "\n",
    "        print('Seen labels: \\t'  + str(train_labels) )\n",
    "        print('Given labels: \\t' + str(labels))\n",
    "        print('max_box_per_image: \\t' + str(max_box_per_image))\n",
    "\n",
    "        # return None, None, None if some given label is not in the dataset\n",
    "        if len(overlap_labels) < len(labels):\n",
    "            print('Label error in annotations')\n",
    "            return None, None, None\n",
    "    else:\n",
    "        print('No labels are provided. Train on all seen labels.')\n",
    "        print(train_labels)\n",
    "        labels = train_labels.keys()\n",
    "\n",
    "    max_box_per_image = max([len(inst['object']) for inst in (train_ints + valid_ints)])\n",
    "\n",
    "    return train_ints, valid_ints, sorted(labels), max_box_per_image\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(saved_weights_name, tensorboard_logs, model_to_save):\n",
    "    makedirs(tensorboard_logs)\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor     = 'loss', \n",
    "        min_delta   = 1e-5, \n",
    "        patience    = 5, \n",
    "        mode        = 'min', \n",
    "        verbose     = 1\n",
    "    )\n",
    "    checkpoint = CustomModelCheckpoint(\n",
    "        model_to_save   = model_to_save,\n",
    "        filepath        = saved_weights_name,# + '{epoch:02d}.h5', \n",
    "        monitor         = 'loss', \n",
    "        verbose         = 1, \n",
    "        save_best_only  = True, \n",
    "        mode            = 'min', \n",
    "        period          = 1\n",
    "    )\n",
    "    reduce_on_plateau = ReduceLROnPlateau(\n",
    "        monitor  = 'loss',\n",
    "        factor   = 0.1,\n",
    "        patience = 3,\n",
    "        verbose  = 1,\n",
    "        mode     = 'min',\n",
    "        epsilon  = 0.01,\n",
    "        cooldown = 0,\n",
    "        min_lr   = 0\n",
    "    )\n",
    "    tensorboard = CustomTensorBoard(\n",
    "        log_dir                = tensorboard_logs,\n",
    "        write_graph            = True,\n",
    "        write_images           = True,\n",
    "    )    \n",
    "    return [early_stop, checkpoint, reduce_on_plateau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "                nb_class, \n",
    "                anchors, \n",
    "                max_box_per_image, \n",
    "                max_grid, batch_size, \n",
    "                warmup_batches, \n",
    "                ignore_thresh, \n",
    "                multi_gpu, \n",
    "                saved_weights_name, \n",
    "                lr,\n",
    "                grid_scales,\n",
    "                obj_scale,\n",
    "                noobj_scale,\n",
    "                xywh_scale,\n",
    "                class_scale  \n",
    "            ):\n",
    "    if multi_gpu > 1:\n",
    "        with tf.device('/cpu:0'):\n",
    "            template_model, infer_model = model(\n",
    "                nb_class            = nb_class, \n",
    "                anchors             = anchors, \n",
    "                max_box_per_image   = max_box_per_image, \n",
    "                max_grid            = max_grid, \n",
    "                batch_size          = batch_size//multi_gpu, \n",
    "                warmup_batches      = warmup_batches,\n",
    "                ignore_thresh       = ignore_thresh,\n",
    "                grid_scales         = grid_scales,\n",
    "                obj_scale           = obj_scale,\n",
    "                noobj_scale         = noobj_scale,\n",
    "                xywh_scale          = xywh_scale,\n",
    "                class_scale         = class_scale\n",
    "            )\n",
    "    else:\n",
    "        template_model, infer_model = model(\n",
    "            nb_class            = nb_class, \n",
    "            anchors             = anchors, \n",
    "            max_box_per_image   = max_box_per_image, \n",
    "            max_grid            = max_grid, \n",
    "            batch_size          = batch_size, \n",
    "            warmup_batches      = warmup_batches,\n",
    "            ignore_thresh       = ignore_thresh,\n",
    "            grid_scales         = grid_scales,\n",
    "            obj_scale           = obj_scale,\n",
    "            noobj_scale         = noobj_scale,\n",
    "            xywh_scale          = xywh_scale,\n",
    "            class_scale         = class_scale\n",
    "        )  \n",
    "\n",
    "    # load the pretrained weight if exists, otherwise load the backend weight only\n",
    "    if os.path.exists(saved_weights_name): \n",
    "        print(\"\\nLoading pretrained weights.\\n\")\n",
    "        template_model.load_weights(saved_weights_name)\n",
    "    \n",
    "    if multi_gpu > 1:\n",
    "        train_model = multi_gpu_model(template_model, gpus=multi_gpu)\n",
    "    else:\n",
    "        train_model = template_model      \n",
    "\n",
    "    #optimizer = Adam(lr=lr, clipnorm=0.001)\n",
    "    optimizer = RMSprop(lr=lr, rho=0.9, epsilon=1e-08, decay=0.0,clipnorm=0.001)\n",
    "    train_model.compile(loss=dummy_loss, optimizer=optimizer)             \n",
    "\n",
    "    return train_model, infer_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annot_folder  = 'data/malaria_phone_dataset/train/'\n",
    "train_image_folder  = 'data/malaria_phone_dataset/train/'\n",
    "valid_annot_folder  = 'data/malaria_phone_dataset/valid/'\n",
    "valid_image_folder  = 'data/malaria_phone_dataset/valid/'\n",
    "train_cache_name    = 'data/train_malaria_phone_dataset.pkl'\n",
    "valid_cache_name    = 'data/valid_malaria_phone_dataset.pkl'\n",
    "labels              = [\"mp\"]\n",
    "tensorboard_dir     = 'logs/'\n",
    "num_anchors         = 9\n",
    "anchors             = [19,22, 20,22, 22,23, 27,38, 28,28, 34,22, 39,31, 39,41, 49,48]\n",
    "\n",
    "''''Achors for different image size range. \n",
    "    To get better results the range between min and max should be less than 128 \n",
    "#[24,26, 33,47, 38,38, 40,29, 46,48, 50,60, 52,39, 59,52, 66,67]  net_size = 736\n",
    "#[19,22, 20,22, 22,23, 27,38, 28,28, 34,22, 39,31, 39,41, 49,48]  net_size = 544\n",
    "#[11,13, 14,15, 16,24, 18,18, 21,21, 22,14, 25,27, 27,21, 31,31]  net_size = 352\n",
    "#[7,7, 10,8, 10,14, 10,11, 12,11, 13,15, 16,11, 17,16, 20,20]     net_size = 224 \n",
    "'''\n",
    "\n",
    "\n",
    "batch_size          = 16\n",
    "min_input_size      = 480\n",
    "max_input_size      = 608\n",
    "net_size            = 544\n",
    "grid_scales         = [4,2,1]\n",
    "obj_scale           = 5\n",
    "noobj_scale         = 1\n",
    "xywh_scale          = 1\n",
    "class_scale         = 1\n",
    "downsample          = 32\n",
    "saved_weights_name  = 'weights/weights_phone_dataset/weights_480-6080.h5'\n",
    "warmup_epochs       = 3\n",
    "train_times         = 10\n",
    "valid_times         = 1\n",
    "gpus                = \"\"\n",
    "ignore_thresh       = 0.35\n",
    "learning_rate       = 4.5e-4\n",
    "epochs              = 10\n",
    "debug               = 1\n",
    "\n",
    "\n",
    "\n",
    "#Parse annotations \n",
    "train_ints, valid_ints, labels, max_box_per_image = create_training_instances(train_annot_folder,\n",
    "                                                           train_image_folder,\n",
    "                                                           train_cache_name,\n",
    "                                                           valid_annot_folder,\n",
    "                                                           valid_image_folder,\n",
    "                                                           valid_cache_name,\n",
    "                                                           labels)\n",
    "\n",
    "#Generate batches for training andd validation    \n",
    "train_generator = create_batch(\n",
    "    instances           = train_ints, \n",
    "    anchors             = anchors,   \n",
    "    labels              = labels,        \n",
    "    downsample          = downsample , # ratio between network input's size and network output's size, 32 for YOLOv3\n",
    "    max_box_per_image   = max_box_per_image,\n",
    "    batch_size          = batch_size, \n",
    "    min_net_size        = min_input_size, \n",
    "    max_net_size        = max_input_size ,\n",
    "    net_size            = net_size,\n",
    "    shuffle             = True, \n",
    "    jitter              = True, \n",
    "    norm                = None\n",
    ")\n",
    "    \n",
    "valid_generator = create_batch(\n",
    "    instances           = valid_ints, \n",
    "    anchors             = anchors,   \n",
    "    labels              = labels,        \n",
    "    downsample          = downsample , # ratio between network input's size and network output's size, 32 for YOLOv3\n",
    "    max_box_per_image   = max_box_per_image,\n",
    "    batch_size          = batch_size ,\n",
    "    min_net_size        = min_input_size, \n",
    "    max_net_size        = max_input_size,\n",
    "    net_size            = net_size,\n",
    "    shuffle             = True, \n",
    "    jitter              = False, \n",
    "    norm                = normalize\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check image and annotations. Ensure that image augumentaions corrects the bouding boxes\n",
    "image = train_generator [0][0][0][0]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(image.astype('uint8'))\n",
    "#plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create model\n",
    "if os.path.exists(saved_weights_name): \n",
    "    warmup_epochs = 0\n",
    "warmup_batches = warmup_epochs * train_times*len(train_generator)  \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "multi_gpu = len(gpus.split(','))\n",
    "\n",
    "train_model, infer_model = create_model(\n",
    "    nb_class            = len(labels), \n",
    "    anchors             = anchors, \n",
    "    max_grid            = [max_input_size,max_input_size], \n",
    "    max_box_per_image   = max_box_per_image,    \n",
    "    batch_size          = batch_size, \n",
    "    warmup_batches      = warmup_batches,\n",
    "    ignore_thresh       = ignore_thresh,\n",
    "    multi_gpu           = multi_gpu,\n",
    "    saved_weights_name  = saved_weights_name,\n",
    "    lr                  = learning_rate,\n",
    "    grid_scales         = grid_scales,\n",
    "    obj_scale           = obj_scale,\n",
    "    noobj_scale         = noobj_scale,\n",
    "    xywh_scale          = xywh_scale,\n",
    "    class_scale         = class_scale\n",
    ")\n",
    "\n",
    "#start trainng\n",
    "\n",
    "callbacks = create_callbacks(saved_weights_name, tensorboard_dir, infer_model)\n",
    "i =0\n",
    "while i<=15:\n",
    "    \n",
    "    #reload the bathes fr each training iteration\n",
    "    train_generator = create_batch(\n",
    "    instances           = train_ints, \n",
    "    anchors             = anchors,   \n",
    "    labels              = labels,        \n",
    "    downsample          = downsample , \n",
    "    max_box_per_image   = max_box_per_image,\n",
    "    batch_size          = batch_size, \n",
    "    min_net_size        = min_input_size, \n",
    "    max_net_size        = max_input_size ,\n",
    "    net_size            = net_size,\n",
    "    shuffle             = True, \n",
    "    jitter              = True, \n",
    "    norm                = normalize)\n",
    "\n",
    "\n",
    "    saved_weights  = saved_weights_name[:-3]+'_'+str(i)+'.h5'\n",
    "    \n",
    "    if i>0:\n",
    "        epochs = 50\n",
    "        warmup_epochs = 0\n",
    "        checkPoint= saved_weights_name[:-3]+'_'+str(i-1)+'.h5'\n",
    "        train_model.load_weights(checkPoint)\n",
    "        print('Saved model loaded: ',  checkPoint)\n",
    "\n",
    "    train_model.fit_generator(\n",
    "        generator        = train_generator, \n",
    "        steps_per_epoch  = len(train_generator) * train_times, \n",
    "        epochs           = epochs+ warmup_epochs, \n",
    "        verbose          = 1,\n",
    "        validation_data  = valid_generator,\n",
    "        validation_steps = len(valid_generator) * valid_times,\n",
    "        callbacks        = callbacks, \n",
    "        workers          = 10,\n",
    "        max_queue_size   = 20,\n",
    "        shuffle         =  True\n",
    "    )\n",
    "    i +=1\n",
    "    \n",
    "    \n",
    "    train_model.save_weights(saved_weights)\n",
    "    \n",
    "    \n",
    "\n",
    "    #eavlate MAP for entire validations set\n",
    "    average_precisions = evaluate(infer_model, \n",
    "                                  valid_generator,\n",
    "                                  iou_threshold=0.3,\n",
    "                                  obj_thresh=0.5,\n",
    "                                  nms_thresh=0.05,\n",
    "                                  net_h=net_size,\n",
    "                                  net_w=net_size)\n",
    "\n",
    "    # print the score\n",
    "    for label, average_precision in average_precisions.items():\n",
    "        print(labels[label] + ': {:.4f}'.format(average_precision))\n",
    "    print('mAP: {:.4f}'.format(sum(average_precisions.values()) / len(average_precisions))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
